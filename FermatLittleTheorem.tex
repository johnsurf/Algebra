\section{Some Results in the Theory of Numbers}

\begin{definition}
If $a$ and $b$ are two integers such that $a-b$ is divisible by $n$, we say that $a$ is congruent to $b$ modulo $n$, and write $a\equiv b\mod n$, or merely $a\equiv b(n)$.
\end{definition}


\begin{theorem}Lagrange's theorem.\\
The order of any subgroup of a finite group is a factor of the order of the group.\\
The order of a finite group $G$ is a multiple of the order of every one of its subgroups.
\end{theorem}

Suppose $H$ is a subgroup of $G$, where the order of $G$ is $n$ and that of $H$ is $m$.\\
The whole group $G$ may be decomposed into cosets $gH$ relative to $H$. The number of elements in each coset must be $m$, since the coset $gH$ is formed by
taking all the elements of $H$ and pre-multiplying them by $g$, and all the elements so formed are different by the Cancellation Law. But the cosets are completely disjoint.
Hence if there are $r$ cosets we must have that $n = mr$, and so $m$ is a factor of $n$.\\

Each element $a$ of $G$ generates a cyclic subgroup, whose order is simple the order of $a$. Therefore we have: 

\begin{corollary}{(Corollary 1):}
Every element of a finite group $G$ has as order a divisor of the order of $G$.
\end{corollary}

\begin{corollary}{(Corollary 2):}
Every group $G$ of prime order $p$ is cyclic.
\end{corollary}
\begin{proof}
For the cyclic subgroup $A$ generated by any element $a\ne e$ in such a group has an order $n>1$ dividing $p$. But this implies $n=p$, and so $G=A$ is cyclic.\qed
\end{proof}

\begin{corollary}{(Corollary 3):}
The only abstract groups of order four are the cyclic group of that order and the four-group (Vierergruppe).
\end{corollary}
\begin{proof}
If a group $G$ has order 4, contains and element of order 4, it is cyclic. Otherwise, by Corollary 1, all elements of $G$ except $e$ must have order 2. 
Call them $a, b, c$. By the cancellation law, $ab$ cannot be either $ac = a, eb = b,$ of $aa = e$; hence $ab=e$. By symmetry, $ac = ca = b, bc = cb = a, ba = c$. But these, together with $a^2 = b^2 =  c^2 = e$, and $ex = xe = x$ for all $x$, give the multiplication table of the four-group.\qed
\end{proof}

\begin{theorem}{(Fermat's Little Theorem):}
If $p$ is prime, $a^p\equiv a(p)$, and if $a$ is not a mulltiple of $p$, then $a^{p-1} \equiv 1 (p)$ 
\end{theorem}

\begin{proof}
(1) The numbers $a, 2a, 3a, ..., (p-1)a$ are all different modulo $p$ if $a$ is not a multiple of $p$, and so they must be $1,2,...,(p-1)$ modulo $p$ in some order. Thus
$$ a.2a.3a ... (p-1)a \equiv 1.2.3 ... (p-1).$$
Hence $a^{(p-1)} \equiv 1(p)$. Thus $a^p \equiv a(p)$ if $a$ is not a multiple of $p$, and this latter result is true also if $a$ is a multiple of $p$, since then both sides are 0. Hence it is true for all $a$.\qed
\end{proof}

\begin{proof}
(2) The multiplication group mod p (excluding zero) has $(p-1)$ elements. The order of any element $a$ of this group is then a divisor of $(p-1)$, by Corollary 1, so that $a^{(p-1)}\equiv 1(p)$ whenever $a\ne 0(p)$. If we multiply by $a$ or both sides, we obtain the desired congruence, except for the case $a\equiv 0(p)$, for which the conclusion is trivially true.\qed
\end{proof}

\begin{proof}
(3) For a fixed prime $p$, let $P(n)$ be the proposition that $n^p \equiv n(p)$.  Then $P(0)$ and $P(1)$ are obvious. In the binomial expansion for $(n+1)^p$, every coefficient except the first and the last is divisible by $p$, hence $(n+1)^p \equiv n^p + 1 (p)$, whence $P(n)$ implies $(n+1)^p \equiv n + 1(p)$, which is the proposition $P(n+1)$.\qed
\end{proof}

\begin{theorem}{(Wilson's Theorem):}
Let $p>2$ be a prime number. The field $\Z_p$ is the splitting field of $x^p - x$.
\end{theorem}

\begin{proof}
Since $\Z_p$ is the splitting field of $x^p - x$, we have $$x^p - x = x(x-1)(x-2)\hdots (x-(p-1)).$$Thus $$x^{(p-1)} - 1 = (x-1)(x-2)\hdots(x- (p-1)),$$
and substituting $x=0$ gives 
$$-1 = (-1)(-2) \hdots (-(p-1)).$$
There are an even number of factos on the right hand side, so the minus signs cancel out, leaving
$$(p-1)! \equiv -1 (\mod{p}),$$ which is Wilson's Theorem.
\end{proof}


%\begin{array}{l}
%0 \quad \hbox{if} \quad i\neq j \\
%E[e_j^2] \quad \hbox{if} \quad i=j \\
%\end{array}$$ 

%\begin{eqnarray*}
%E[\Delta B^2] &=& E[2\,B\, \Delta B + (\Delta B)^2]\\
%&=& 2B\, \Delta B + \sigma^2 \Delta t
%end{eqnarray*}

%\begin{eqnarray*}
%&\null& E[( {1\over2}B_t^2 - {1\over2}t - \sum_j B_j \Delta B_j)^2] \\
%&=&E[{1\over4} B_t^4 + {1\over4}t^2 + (\sum_j B_j \Delta B_j)^2 - B_t^2\cdot \sum_j B_j\Delta B_j - {1\over2}tB_t^2 + t\cdot \sum_j B_j\Delta B_j] \\
%&=& {3\over4}t^2 + {1\over4}t^2 + E[(\sum B_j \Delta B_j)^2] - E[B_t^2\cdot \sum B_j\Delta B_j] - {1\over2}t^2 + 0. 
%\end{eqnarray*}

%Also, $$E[(\sum B_j \Delta B_j)^2] = \sum_{i,j} E[B_iB_j\Delta B_i \Delta B_j] = \sum_iE[B_i^2(\Delta B_i)^2]  \sum_i t_i \Delta t_i$$ and
%\begin{eqnarray*}
%&\null&E[B_t^2\cdot \sum B_j \Delta B_j] = \sum_jE[B_t^2B_j\Delta B_j] = \sum_j E[\{(B_t - B_{j+1}) + \Delta B_j + B_j\}^2\cdot B_j\cdot \Delta B_j]\\
%&=&\sum_jE[(B_t - B_{j+1})^2 B_j\Delta B_j] + \sum_j E[B_j\cdot (\Delta B_j)^3] + \sum_jE[B_j^3\cdot \Delta B_j] \\
%&+& 2\sum E[(B_t - B_{j+1}) B_j\Delta B^2_j] + 2\cdot\sum_j E[(B_t-B_{j+1})B_j^2\Delta B_j + 2 \sum_j E[B_j^2\Delta B_j^2]\\
%&=& 0 + 0 + 0 + 0 + 0 + 2\sum_j t_j\cdot \Delta t_j
%\end{eqnarray*}
